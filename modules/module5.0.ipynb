{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba87692a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#countvectorizer-LDA and calculation of perplexity #module 5.0 \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(\"../Files/Figure3/Table7.csv\")\n",
    "df1[\"period\"]=1\n",
    "df2 = pd.read_csv(\"../Files/Figure3/Table8.csv\")\n",
    "df2[\"period\"]=2\n",
    "df3 = pd.read_csv(\"../Files/Figure3/Table9.csv\")\n",
    "df3[\"period\"]=3\n",
    "df4 = pd.read_csv(\"../Files/Figure3/Table10.csv\")\n",
    "df4[\"period\"]=4\n",
    "df = pd.concat([df1,df2,df3,df4],axis=0)\n",
    "df.drop_duplicates(subset=\"PMID\",inplace=True)\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "display(df)\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_sci_lg\")\n",
    "with open(\"../Files/SupplementalTables/SupplementalTable1.txt\", \"r\", encoding='utf-8') as f:\n",
    "    stopwords = [w.strip() for w in f]\n",
    "print(\"=====\\n stopwords\\n\")\n",
    "print(stopwords)\n",
    "\n",
    "dic_corpus={}\n",
    "for raw in df[[\"PMID\",\"abstract\"]].itertuples():\n",
    "    text =\"\"\n",
    "    text_cleaned=\"\"\n",
    "    doc = nlp(str(raw[2]))\n",
    "    for ent in doc.ents:\n",
    "        text = text+\" \"+str(ent).lower()\n",
    "        ls = text.split()\n",
    "    for i in ls:\n",
    "        if i not in stopwords:\n",
    "            text_cleaned = text_cleaned+\" \"+i\n",
    "    print(raw[1])\n",
    "    print(text_cleaned)\n",
    "    dic_corpus[raw[1]]=text_cleaned\n",
    "\n",
    "\n",
    "#1 countvectorizer\n",
    "corpus = [text_cleaned for text_cleaned in dic_corpus.values()]\n",
    "vectorizer = CountVectorizer()\n",
    "count = vectorizer.fit_transform(corpus)\n",
    "count_name=vectorizer.get_feature_names_out()\n",
    "\n",
    "count_vec= count.toarray()\n",
    "count_pd = pd.DataFrame(count_vec,index = dic_corpus.keys(),columns=count_name)\n",
    "\n",
    "\n",
    "#2 LDA and n_topic optimization\n",
    "perplexity = {}\n",
    "for i in range(10,21):\n",
    "    lda = LatentDirichletAllocation(n_components=i,random_state=16)#lda\n",
    "    lda.fit(count_vec)\n",
    "    perp = lda.perplexity(count_vec)\n",
    "    perplexity[i]=perp\n",
    "    print(\"topic:{}, perplexity:{}\".format(i,perp))\n",
    "    lda_value = lda.fit_transform(count_vec)#probability of each topic\n",
    "    lda_index = np.argmax(lda_value,axis=1)#maximum of the probability of each group = component\n",
    "    df_lda_index = pd.DataFrame(lda_index,index=dic_corpus.keys(),columns =[\"topic\"])#dic_corpus.keys()=PMID\n",
    "    df_period = df[[\"PMID\",\"period\"]].set_index([\"PMID\"])\n",
    "    df_lda = pd.concat([df_lda_index,df_period],axis=1)\n",
    "    display(df_lda)\n",
    "    df_lda.to_csv(\"../Files/Figure4/PMID_topic/Table{}.csv\".format(i+13))\n",
    "    \n",
    "    print(\"topic words top-10\")\n",
    "    topic_words = {}\n",
    "    weight_words = {}\n",
    "    n_top_words = 10\n",
    "    for topic, comp in enumerate(lda.components_):\n",
    "        word_idx = np.argsort(comp)[::-1][:n_top_words]\n",
    "        topic_words[topic] = [count_name[i] for i in word_idx]\n",
    "        weight_words[topic] = np.sort(comp)[::-1][:n_top_words]\n",
    "    for topic, words in topic_words.items():\n",
    "        print('Topic: %d' % topic)\n",
    "        print('  %s' % ', '.join(words))\n",
    "    \n",
    "    #period-component\n",
    "    dic_period = {}\n",
    "    for j in range(i):\n",
    "        ls_component = []\n",
    "        for period in range(1,5):\n",
    "            ls_component.append(len(df_lda[(df_lda[\"period\"]==period)&(df_lda[\"topic\"]==j)]))\n",
    "        dic_period[j]=ls_component\n",
    "\n",
    "    df_period = pd.DataFrame(dic_period.values(),index = dic_period.keys(),columns=[\"period I\",\"period II\",\"period III\",\"period IV\"])\n",
    "    df_topic = pd.DataFrame(topic_words.values(),index = topic_words.keys(),columns=[\"word{}\".format(i) for i in range(n_top_words)])\n",
    "    df_weight = pd.DataFrame(weight_words.values(),index = weight_words.keys(),columns=[\"weight{}\".format(i)for i in range(n_top_words)])\n",
    "    df_period_topic = pd.concat([df_topic,df_weight,df_period],axis=1)\n",
    "    df_period_topic.to_csv(\"../Files/Figure4/Topic_word/Table{}.csv\".format(i+24))    \n",
    "df_perplexity = pd.DataFrame(perplexity.values(),index=perplexity.keys())\n",
    "df_perplexity.to_csv(\"../Files/Figure4/Table45.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a4ad6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
