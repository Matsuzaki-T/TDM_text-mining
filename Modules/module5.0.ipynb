{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba87692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#countvectorizer-LDA and calculation of perplexity remove NaN #module 5.0\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "def lda_create(df, name, vec, i): #df = raw data (Pandas DataFrame), name = word name list, vec = Bag of words matrix #i = the number of topics\n",
    "    lda = LatentDirichletAllocation(n_components=i,random_state=1)#lda\n",
    "    lda.fit(vec)\n",
    "    perp = lda.perplexity(vec)\n",
    "    print(\"topic:{}, perplexity:{}\".format(i,perp))\n",
    "    lda_value = lda.fit_transform(vec)#probability of each topic\n",
    "    lda_index = np.argmax(lda_value,axis=1)#maximum of the probability of each group = component\n",
    "    df_lda_index = pd.DataFrame(lda_index,index=df[\"PMID\"],columns =[\"topic\"])#dic_corpus.keys()=PMID\n",
    "    df_period = df[[\"PMID\",\"period\"]].set_index([\"PMID\"])\n",
    "    df_lda = pd.concat([df_lda_index,df_period],axis=1)\n",
    "    display(df_lda)\n",
    "\n",
    "    #topic words\n",
    "    print(\"topic words top-10\")\n",
    "    topic_words = {}\n",
    "    weight_words = {}\n",
    "    n_top_words = 10\n",
    "    for topic, comp in enumerate(lda.components_):\n",
    "        word_idx = np.argsort(comp)[::-1][:n_top_words]\n",
    "        topic_words[topic] = [name[j] for j in word_idx]\n",
    "        weight_words[topic] = np.sort(comp)[::-1][:n_top_words]\n",
    "    for topic, words in topic_words.items():\n",
    "        print('Topic: %d' % topic)\n",
    "        print('  %s' % ', '.join(words))\n",
    "\n",
    "    #period-component\n",
    "    dic_period = {}\n",
    "    for j in range(i):\n",
    "        ls_component = []\n",
    "        for period in range(1,5):\n",
    "            ls_component.append(len(df_lda[(df_lda[\"period\"]==period)&(df_lda[\"topic\"]==j)]))\n",
    "        dic_period[j]=ls_component\n",
    "\n",
    "    df_period = pd.DataFrame(dic_period.values(),index = dic_period.keys(),columns=[\"period I\",\"period II\",\"period III\",\"period IV\"])\n",
    "    df_topic = pd.DataFrame(topic_words.values(),index = topic_words.keys(),columns=[\"word{}\".format(i) for i in range(n_top_words)])\n",
    "    df_weight = pd.DataFrame(weight_words.values(),index = weight_words.keys(),columns=[\"weight{}\".format(i)for i in range(n_top_words)])\n",
    "    df_period_topic = pd.concat([df_topic,df_weight,df_period],axis=1)\n",
    "    display(df_period_topic)\n",
    "\n",
    "    return perp, df_lda, df_period_topic\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(\"../Files/Figure3/Table7.csv\")\n",
    "df1[\"period\"]=1\n",
    "df2 = pd.read_csv(\"../Files/Figure3/Table8.csv\")\n",
    "df2[\"period\"]=2\n",
    "df3 = pd.read_csv(\"../Files/Figure3/Table9.csv\")\n",
    "df3[\"period\"]=3\n",
    "df4 = pd.read_csv(\"../Files/Figure3/Table10.csv\")\n",
    "df4[\"period\"]=4\n",
    "df = pd.concat([df1,df2,df3,df4],axis=0)\n",
    "df.drop_duplicates(subset=\"PMID\",inplace=True)\n",
    "df.dropna(subset=[\"abstract\"], inplace=True)#ここがmodule 5.0と違う\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "display(df)\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_sci_lg\")\n",
    "with open(\"../Files/SupplementalTables/SupplementalTableS2.txt\", \"r\", encoding='utf-8') as f:\n",
    "    stopwords = [w.strip() for w in f]\n",
    "print(\"=====\\n stopwords\\n\")\n",
    "print(stopwords)\n",
    "\n",
    "dic_corpus={}\n",
    "for raw in df[[\"PMID\",\"abstract\"]].itertuples():\n",
    "    text =\"\"\n",
    "    text_cleaned=\"\"\n",
    "    doc = nlp(str(raw[2]))\n",
    "    for ent in doc.ents:\n",
    "        text = text+\" \"+str(ent).lower()\n",
    "        ls = text.split()\n",
    "    for i in ls:\n",
    "        if i not in stopwords:\n",
    "            text_cleaned = text_cleaned+\" \"+i\n",
    "    print(raw[1])\n",
    "    print(text_cleaned)\n",
    "    dic_corpus[raw[1]]=text_cleaned\n",
    "\n",
    "corpus = [text_cleaned for text_cleaned in dic_corpus.values()]\n",
    "#1 countvectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "count = vectorizer.fit_transform(corpus)\n",
    "count_name=vectorizer.get_feature_names_out()\n",
    "\n",
    "count_vec= count.toarray()\n",
    "count_pd = pd.DataFrame(count_vec,index = dic_corpus.keys(),columns=count_name)\n",
    "print(\"\\n=====\\ntifdf_pandas\\n=====\\n\")\n",
    "display(count_pd)\n",
    "\n",
    "#2 TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(corpus)\n",
    "tfidf_name=vectorizer.get_feature_names_out()\n",
    "\n",
    "tfidf_vec= tfidf.toarray()\n",
    "tfidf_pd = pd.DataFrame(tfidf_vec,index=dic_corpus.keys(),columns=tfidf_name)\n",
    "print(\"\\n=====\\ntifdf_pandas\\n=====\\n\")\n",
    "display(tfidf_pd)\n",
    "\n",
    "#3 t-SNE\n",
    "print(\"t-SNE\")\n",
    "tsne = TSNE(n_components=2, random_state=0)#componentsで分類の数\n",
    "W=tsne.fit_transform(count_vec)\n",
    "W_tfidf=tsne.fit_transform(tfidf_vec)\n",
    "\n",
    "#4 LDA (without TF-IDF) and n_topic optimization\n",
    "perplexity = {}\n",
    "for i in range(10,21):\n",
    "    perp, df_lda, df_period_topic = lda_create(df,count_name,count_vec,i)\n",
    "    perplexity[i]=perp\n",
    "    W_lda = pd.concat([pd.DataFrame(W,index=df[\"PMID\"],columns = [\"col1\", \"col2\"]),df_lda], axis=1)\n",
    "    W_lda.to_csv(\"../Files/Figure4/Table{}_rs1.csv\".format(i+9))\n",
    "    df_period_topic.to_csv(\"../Files/Figure4/Table{}_rs1.csv\".format(i+20))\n",
    "\n",
    "\n",
    "df_perplexity = pd.DataFrame(perplexity.values(),index=perplexity.keys())\n",
    "df_perplexity.to_csv(\"../Files/Figure4/Table41_rs1.csv\")\n",
    "\n",
    "#5 LDA (with TF-IDF) and n_topic optimization\n",
    "perplexity_tfidf = {}\n",
    "for i in range(10,21):\n",
    "    perp, df_lda, df_period_topic = lda_create(df,tfidf_name,tfidf_vec,i)\n",
    "    perplexity_tfidf[i]=perp\n",
    "    W_lda_tfidf = pd.concat([pd.DataFrame(W_tfidf,index=df[\"PMID\"],columns = [\"col1\", \"col2\"]),df_lda], axis=1)\n",
    "    W_lda_tfidf.to_csv(\"../Files/Figure4/Table{}_rs1.csv\".format(i+32))\n",
    "    df_period_topic.to_csv(\"../Files/Figure4/Table{}_rs1.csv\".format(i+43))\n",
    "\n",
    "\n",
    "df_perplexity_tfidf = pd.DataFrame(perplexity_tfidf.values(),index=perplexity_tfidf.keys())\n",
    "df_perplexity_tfidf.to_csv(\"../Files/Figure4/Table64_rs1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a4ad6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
