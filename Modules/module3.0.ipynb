{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71415fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#module 3.0\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def export(input_path,output_path):\n",
    "\n",
    "    #get pmids\n",
    "    with open(input_path) as f:\n",
    "        pmid_ls = f.read().splitlines()\n",
    "    pmid_ls = sorted(pmid_ls)#sort pmid list\n",
    "    dic_title ={}#dictionary to store abstracts\n",
    "    dic_abst = {}#dictionary to store abstracts\n",
    "    for pmid in pmid_ls:\n",
    "        dic_title[pmid]=\"Not found\"\n",
    "        dic_abst[pmid]=\"Not found\"\n",
    "    i = 0#batch\n",
    "    while 100*i < len(pmid_ls):#retrieve 100 abstracts in each batch\n",
    "        html = \"https://www.ncbi.nlm.nih.gov/research/pubtator-api/publications/export/pubtator?pmids=\"\n",
    "        pmid_ls_part = pmid_ls[100*i:min(100*(i+1),len(pmid_ls))]\n",
    "        for pmid in pmid_ls_part:\n",
    "            html = html+str(pmid)+\",\"\n",
    "        html = html[:-1]#remove last \",\"\n",
    "        #get contents\n",
    "        while True:#to prevent HTTP403 error\n",
    "            try:\n",
    "                response = urllib.request.urlopen(html)\n",
    "                break\n",
    "            except:\n",
    "                time.sleep(10)\n",
    "        print(\"url:\", response.geturl())\n",
    "        content = response.readlines()\n",
    "        content_str = []#change content datatype to str\n",
    "        for line in content:\n",
    "            content_str.append(str(line))\n",
    "        for text in content_str:\n",
    "            if \"|t|\" in text:\n",
    "                title = text[text.find(\"|t|\")+3:-3]#get after |t| tag and remov \\n [:-3]\n",
    "                dic_title[text[2:text.find(\"|t|\")]]=title\n",
    "            if \"|a|\" in text:\n",
    "                abst = text[text.find(\"|a|\")+3:-3]#get after |a| tagã€€and remove \\n [:-3]\n",
    "                dic_abst[text[2:text.find(\"|a|\")]]=abst\n",
    "        i = i+1\n",
    "        #merge pmid_ls, abs_ls\n",
    "    df_index =pd.DataFrame(dic_title.keys(),columns=[\"PMID\"],index=dic_title.keys())\n",
    "    df_title =pd.DataFrame(dic_title.values(),columns=[\"title\"],index=dic_title.keys())\n",
    "    df_abst =pd.DataFrame(dic_abst.values(),columns=[\"abstract\"],index=dic_abst.keys())\n",
    "    df=pd.concat([df_index,df_title,df_abst],axis=1)\n",
    "    df.set_index(\"PMID\", inplace=True)\n",
    "    display(df)\n",
    "    df.to_csv(output_path)\n",
    "\n",
    "    #retrieve PMID not stored in PTC\n",
    "    df_none = df[(df[\"title\"] == \"Not found\")|(df[\"abstract\"] == \"Not found\")]\n",
    "\n",
    "    print(str(len(pmid_ls)-len(df_none.index))+\" titles/abstracts were successfully exported.\")\n",
    "    if df_none.size>0:\n",
    "        id_none =\"\"\n",
    "        for id in df_none.index:\n",
    "            id_none = id_none+id+\" \"\n",
    "        print(\"Publications of \"+id_none+\" were not found in PTC. Please add titles and abstracts manually.\")\n",
    "    response.close()\n",
    "\n",
    "\n",
    "input_path = \"../pmid.txt\"\n",
    "output_path = \"../export.csv\"\n",
    "export(input_path,output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b66350c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "af034507c1b97134fe3199f2364f9cb32fe7dc453cfd3a79189cc6de37914607"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
